{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5kAP3MS0uAM"
   },
   "source": [
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc4cEhsD0uDu"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this task we aim to predict the relevance of certain articles, described in `body`, when we produce one of the 50 searches described in `topic`, `narrative`, and `description`.\n",
    "\n",
    "We implemented several supervised machine learning models to predict the relevance of other articles and their respective searches.\n",
    "\n",
    "Our models consist in a logistic regression model, a single-hidden-layer neural network, a deep neural network, and two complex architecture models.\n",
    "While more complex architectures outperformed simpler models, performance is between 83% and 88% accuracy.\n",
    "\n",
    "Our main takeaway from these models is that models which take in two inputs are more effective in search relevance problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi_1gHV60uG1"
   },
   "source": [
    "## Method\n",
    "### The Data\n",
    "The data:\n",
    "We count with a labeled set of 19758 articles and their respective searches, as well as their relevance, and 4884 unlabeled article-search pairs.\n",
    "\n",
    "For each of the article-search pairs we used the following parameters:\n",
    "\n",
    "*   `doc id` - unique id for each article-search pair\n",
    "*   `topic_title` - title of the topic of the search\n",
    "*   `description` - description of the information needed in the search\n",
    "*   `narrative` - description of what is relevant for the search\n",
    "*   `author` - name of the author of the article\n",
    "*   `title` - title of the article\n",
    "*   `body` - text of the main body of the article\n",
    "And in the case of the labeled data:\n",
    "*   `judgement` - relevance article-search pairs. 0 if irrelevant, 1 if relevant.\n",
    "\n",
    "\n",
    "Do note that `topic_title`, `description`, and `narrative` are perfectly correlated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsQ1bpJO1wUf"
   },
   "outputs": [],
   "source": [
    "#Select parquet files with train and test data from device if relevant\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO7uL3H57Vy-"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries for code execution. Note some of these libraries may require additional downloading of packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Input, Embedding, Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXLSMOvm8hF9"
   },
   "outputs": [],
   "source": [
    "#Import data. May need to modify depending on the path in your machine\n",
    "df_train = pd.read_parquet('relevance_train.parquet')\n",
    "df_test = pd.read_parquet('relevance_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLAeSWbM9-QX"
   },
   "outputs": [],
   "source": [
    "#Observe sample of training data and their labels\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiexqBh1BuTz"
   },
   "outputs": [],
   "source": [
    "#Observe sample of test data and their labels\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suwvCpYV-S3_"
   },
   "source": [
    "### Data Pre-processing:\n",
    "As we are dealing with mostly text-based data we need to ensure machines can comprehend the text’s structure, semantics, and context.\n",
    "\n",
    "To do that we first remove noise from the data, in our data this means removing html tags, newline tokens, stopwords, digits, and punctuation.\n",
    "\n",
    "We then want to only keep the meaning of the words. We attempted both lemmatization, and stemming to achieve that stemming yields slightly better results on our data. This data will need to be tokenised (in our case as vectors using sklearn’s TFidVectorizer) for interpretation, which is applied after the validation/training division of the data.\n",
    "\n",
    "Additional data pre-processing involvers transforming NaN data into strings for type-consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5c7Rc7jlB3kn"
   },
   "outputs": [],
   "source": [
    "#Suggested downloads to run code. May be unnecessary if your environment already contains them\n",
    "# Uncomment for download\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5LjDP3E-oce"
   },
   "outputs": [],
   "source": [
    "#Function to remove English stopwords from a sentence\n",
    "\n",
    "#Fetch stopwords in English\n",
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "# Define a function to remove stopwords from a sentence\n",
    "def remove_stop_words(sentence):\n",
    "  '''\n",
    "  sentence --->  unprocessed sentence (str)\n",
    "  output ---> sentence without stop words (str)\n",
    "  '''\n",
    "  # Split the sentence into individual words\n",
    "  words = sentence.split()\n",
    "\n",
    "  # List comprehension to remove stopwords\n",
    "  filtered_words = [word for word in words if word not in stopset]\n",
    "\n",
    "  # Join the filtered words back into a sentence\n",
    "  return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUFkdkiF_BDm"
   },
   "outputs": [],
   "source": [
    "#Define a function to stem all words in a sentence\n",
    "ps = PorterStemmer()\n",
    "def stem (sentence):\n",
    "  '''\n",
    "  sentence --->  unprocessed sentence (str)\n",
    "  output ---> sentence with just stem words (str)\n",
    "  '''\n",
    "    stemmed = []\n",
    "    # Split the sentence into individual words\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        stemmed.append(ps.stem(word))\n",
    "    #Join the stemmed words back into a sentence\n",
    "    return ' '.join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aRzkHuY_FJQ"
   },
   "outputs": [],
   "source": [
    "#NOT USED IN OUR FINAL PRE-PROCESSING METHOD\n",
    "#Define a function to find all lemmas of the words in a sentence\n",
    "wl = WordNetLemmatizer()\n",
    "def lemma (sentence):\n",
    "  '''\n",
    "  sentence --->  unprocessed sentence (str)\n",
    "  output ---> sentence with just lemma of words (str)\n",
    "  '''\n",
    "    lemmas = []\n",
    "    # Split the sentence into individual words\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        lemmas.append(wl.lemmatize(word))\n",
    "    #Join the stemmed words back into a sentence\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_a8rCUP_RGU"
   },
   "outputs": [],
   "source": [
    "#Define a function to perform language processing on dataframe collumn\n",
    "def nlp (iterable):\n",
    "    '''\n",
    "    iterable --->  unprocessed sentence (str)\n",
    "    output ---> sentence of clean preprocessed sentence (str)\n",
    "    '''\n",
    "    processed = []\n",
    "    for element in iterable:\n",
    "        element = str(element)\n",
    "        element = element.lower()\n",
    "        element = ''.join([i for i in element if not i.isdigit()]) #Remove digits from string\n",
    "        element = re.sub(\"\\<.*?\\>\",\" \", element) #Remove all HTML tags\n",
    "        element = element.replace('\\\\n', '') #Remove new line token\n",
    "        element = re.sub(r'[^\\w\\s]','',element) #Remove punctuation\n",
    "        element = remove_stop_words(element) #Call remove stopwords function\n",
    "        #element = lemma(element) #does not add much to the stemming. performs worse than stemming\n",
    "        element = stem(element)\n",
    "        #Add processed element into the list\n",
    "        processed.append(element)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1m7GTkM_guE"
   },
   "outputs": [],
   "source": [
    "#Label encoding for searches. Helps determing correlation between topic_title, description, and narrative\n",
    "def id_creator (iterable):\n",
    "    '''\n",
    "    iterable --->  unprocessed sentence (iter)\n",
    "    output ---> label encoded unique id lists (list)\n",
    "    '''\n",
    "    id = []\n",
    "    id_Dict = {}\n",
    "    for item in iterable:\n",
    "        item = str(item)\n",
    "        if item not in id_Dict:\n",
    "            id_Dict[item] = len(id_Dict) + 1\n",
    "        id.append(id_Dict[item])\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGPHktHA_9CV"
   },
   "outputs": [],
   "source": [
    "#Generate DataFrame with the processed text for train\n",
    "processed_train = {'id': df_train['doc_id'],\n",
    "                   'author': df_train['author'],\n",
    "                   'title': nlp(df_train['title']),\n",
    "                   'topic_id': df_train['topic_id'],\n",
    "                   'topic': nlp(df_train['topic_title']),\n",
    "                   'body': nlp(df_train['body']),\n",
    "                   'description_id': id_creator(df_train['description']),\n",
    "                   'description': nlp(df_train['description']),\n",
    "                   'narrative_id': id_creator(df_train['narrative']),\n",
    "                   'narrative': nlp(df_train['narrative']),\n",
    "                   'judgement':df_train['judgement']}\n",
    "\n",
    "#Convert to dataframe\n",
    "df_train_processed = pd.DataFrame(processed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-ClPYgv_9GI"
   },
   "outputs": [],
   "source": [
    "#Generate DataFrame with the processed text for test\n",
    "processed_test = {'id': df_test['doc_id'],\n",
    "                   'author': df_test['author'],\n",
    "                   'title': nlp(df_test['title']),\n",
    "                   'topic_id': df_test['topic_id'],\n",
    "                   'topic': nlp(df_test['topic_title']),\n",
    "                   'body': nlp(df_test['body']),\n",
    "                   'description_id': id_creator(df_test['description']),\n",
    "                   'description': nlp(df_test['description']),\n",
    "                   'narrative_id': id_creator(df_test['narrative']),\n",
    "                   'narrative': nlp(df_test['narrative'])}\n",
    "\n",
    "#Convert to dataframe\n",
    "df_test_processed = pd.DataFrame(processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPj0EH9mAPEX"
   },
   "outputs": [],
   "source": [
    "#Optional storage. Used to not run pre-processing each time we tested a model\n",
    "\n",
    "#Export processed text to excel\n",
    "df_train_processed.to_excel('relevance_train_processed.xlsx')\n",
    "df_test_processed.to_excel('relevance_test_processed.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7U0Nvt_DcTP"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0AZdQ5dDkRV"
   },
   "outputs": [],
   "source": [
    "df_train_processed = pd.read_excel('relevance_train_processed.xlsx')\n",
    "df_test_processed = pd.read_excel('relevance_test_processed.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kz0g1amAmdA"
   },
   "source": [
    "### Down-sampling\n",
    "\n",
    "Further observation of the data shows the proportion of relevant to irrelevant data is low: 84.28% irrelevant to 15.72% relevant. Such a disparity could cause models to skew towards irrelevance. By implementing this function we lose data quantity for training but gaining better fitted models. We run our model validation on full and down-sampled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xlkoBSMA0pf"
   },
   "outputs": [],
   "source": [
    "#Determine percentage of relevant samples\n",
    "relevant_count = sum(df_train_processed['judgement'])\n",
    "relevant_percentage = relevant_count/len(df_train_processed['judgement'])\n",
    "\n",
    "print('irrelevant:', 1 - relevant_percentage, 'relevant:', relevant_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BF9CfQYmClBc"
   },
   "outputs": [],
   "source": [
    "#Function to produce downsampling with selected seed\n",
    "def down_sampling(X, seed = 42):\n",
    "  '''\n",
    "  Apply down sampling to dataframe\n",
    "  X ---> train set data (pandas DataFrame). Must contain judgement column!\n",
    "  seed ---> selection of random seed that will be used (int)\n",
    "  '''\n",
    "  #Create separate dataframes for relevant and irrelevant searches (0, 1 judgements)\n",
    "  df_relevant = X[X['judgement']==1]\n",
    "  df_irrelevant = X[X['judgement']==0]\n",
    "\n",
    "  #Determine which contains more data\n",
    "  down_needed, down_no_needed = df_irrelevant, df_relevant\n",
    "  if df_relevant.shape[0] > df_irrelevant.shape[0]:\n",
    "    down_needed = df_relevant, df_relevant\n",
    "\n",
    "  #Perform down sampling on relevant list\n",
    "  df_downsampled = down_needed.sample(down_no_needed.shape[0], random_state = seed)\n",
    "\n",
    "  #Concatenate the balanced lists and return final list\n",
    "  return pd.concat([df_downsampled, down_no_needed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LxGj42AESdJ"
   },
   "source": [
    "### Determining the validation set\n",
    "\n",
    "For the validation set determination, we arbitrarily select 20% of the topics and their corresponding articles, as the validation set. Since the test data does not share any topics with the training data. We believe this is representative of the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7O8f4xfElFf"
   },
   "outputs": [],
   "source": [
    "#Function to perform 20% topic validation sets\n",
    "def validation_split(X, size = 0.2, seed = 42):\n",
    "  '''\n",
    "  Select percentage of the topics as validation data\n",
    "  X ---> train set data (pandas DataFrame). Must contain topic column!\n",
    "  size ---> percentage in decimal form of topics selected (float)\n",
    "  seed ---> selection of random seed that will be used (int)\n",
    "  output ---> train (pandas DataFrame), val (pandas DataFrame)\n",
    "  '''\n",
    "  #Get all the unique topic ids\n",
    "  topics = X['topic_id'].unique()\n",
    "\n",
    "  #Select the arbitrary validation topics\n",
    "  topics_val = pd.Series(topics).sample(frac=size, random_state = seed)\n",
    "\n",
    "  #Split df into training and validation sets\n",
    "  train = X[~X['topic_id'].isin(topics_val)]\n",
    "  val = X[X['topic_id'].isin(topics_val)]\n",
    "\n",
    "  return train, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c2dtCPzLIUX"
   },
   "source": [
    "## Models\n",
    "\n",
    "### \"Sparse\" model\n",
    "We acknowledge the 84% accuracy that would be obtained from assigning all entries in the training set a 0 in the `judgement` attribute, and wish to include an “everything is deemed irrelevant” model as our first benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R547MIwZEDot"
   },
   "outputs": [],
   "source": [
    "def sparse(tbd):\n",
    "  '''\n",
    "  tbd ---> data for which we want a prediction (numpy array)\n",
    "  output ---> prediction array\n",
    "  '''\n",
    "\n",
    "  #Create a bucket of 0s of the same length as the labelled data\n",
    "  return [0] * len(list(tbd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F32Kt63yECyI"
   },
   "source": [
    "### Standard Machine Learning model\n",
    "Using standard machine learning techniques for prediction, we feed the `topic_title`, `description`, `narrative`, `body`, `title`, and `judgement` attributes of the training data, and fit these to a random forest model to make the prediction of `judgement` in the validation data. Other machine learning models were tested yielding less accurate results, and some (like Linear Regression) did not converge within 10000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zDoRnugEMKL"
   },
   "outputs": [],
   "source": [
    "def standard(X, y, tbd):\n",
    "  '''\n",
    "  X ---> training data tokenised (numpy array)\n",
    "  y ---> labels of training data (numpy array)\n",
    "  tbd ---> data for which we want a prediction (numpy array)\n",
    "  output ---> prediction array\n",
    "  '''\n",
    "\n",
    "  # Train logistic regression model\n",
    "  model = LogisticRegression(max_iter=10000)\n",
    "  model.fit(X, y)\n",
    "\n",
    "  #Return the prediction\n",
    "  return model.predict(tbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQAaAAgzghDF"
   },
   "outputs": [],
   "source": [
    "def forest(X, y, tbd, estimators = 100):\n",
    "  '''\n",
    "  X ---> training data tokenised (numpy array)\n",
    "  y ---> labels of training data (numpy array)\n",
    "  tbd ---> data for which we want a prediction (numpy array)\n",
    "  estimators ---> number of trees in the forest (int)\n",
    "  output ---> prediction array\n",
    "  '''\n",
    "  model = RandomForestClassifier(n_estimators = estimators, random_state=42)\n",
    "  model.fit(X, y)\n",
    "  return model.predict(tbd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24ikUT1UEMgS"
   },
   "source": [
    "### 3-layer Neural Network\n",
    "Our training data is fed into a neural network of the following structure:\n",
    "\n",
    "Layer 1: Input layer (number of neurons dependent on input shape)\n",
    "\n",
    "Layer 2: Hidden layer (variable neurons)\n",
    "\n",
    "Layer 3: Output layer (1 neuron)\n",
    "\n",
    "We vary the number of neurons in the hidden layer to check its impact on performance in our validation set.\n",
    "\n",
    "We tested several activation functions and layer types. Our final models includes an initial sequential layer, and two dense layers. The hidden layer uses a Rectified Linear Unit activation function. And the output layer uses a sigmoid function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvypylXZETAI"
   },
   "outputs": [],
   "source": [
    "def threeNN (X, y, X_val, y_val, hidden, input_shape, epochs = 10, batch = 32):\n",
    "  '''\n",
    "  X ---> training data tokenised (numpy array)\n",
    "  y ---> labels of training data (numpy array)\n",
    "  X_val ---> validation data tokenised (numpy array)\n",
    "  y_val ---> labels of validation data (numpy array)\n",
    "  hidden ---> number of neurons in hidden layer (int)\n",
    "  input_shape ---> number of neurons in input layer (int)\n",
    "  epoch ---> number of epochs that the network is trained (int)\n",
    "  batch ---> number of samples in a batch (int)\n",
    "  output1 ---> last_accuracy, final accuracy number for training data (int)\n",
    "  output2 ---> val_accuracy, final accuracy number for validation data (int)\n",
    "  '''\n",
    "\n",
    "  #Create 3 layer architecture\n",
    "  model = Sequential()\n",
    "  model.add(Dense(hidden, activation='relu', input_shape = (input_shape,)))\n",
    "  model.add(Dense (1, activation='sigmoid'))\n",
    "\n",
    "  #Compile the model\n",
    "  model.compile(optimizer ='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  #Fit model\n",
    "  history = model.fit(X, y, epochs = epochs, batch_size = batch, validation_data = (X_val, y_val))\n",
    "\n",
    "  #Evaluate model\n",
    "  loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "  #For graphics extract last accuracy\n",
    "  last_accuracy = history.history['accuracy'][-1]\n",
    "  val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "  return last_accuracy, val_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IobafZMdETQl"
   },
   "source": [
    "### Deep Neural Network\n",
    "Expanding on our 3-layer Neural Network model, we use our best performing iteration of the 3-layer neural network and add hidden layers.\n",
    "\n",
    "We test several configurations with different amounts of hidden layers, following the same structure as our 3-layer Neural Network hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RGQJSX2EXi1"
   },
   "outputs": [],
   "source": [
    "def DNN (X, y, X_val, y_val, hidden, hidden_layers, input_shape, epochs = 10, batch =32):\n",
    "  '''\n",
    "  X ---> training data tokenised (numpy array)\n",
    "  y ---> labels of training data (numpy array)\n",
    "  X_val ---> validation data tokenised (numpy array)\n",
    "  y_val ---> labels of validation data (numpy array)\n",
    "  hidden ---> number of neurons in hidden layer (int)\n",
    "  hidden_layers ---> number of hidden layers in the network (int)\n",
    "  input_shape ---> number of neurons in input layer (int)\n",
    "  epoch ---> number of epochs that the network is trained (int)\n",
    "  batch ---> number of samples in a batch (int)\n",
    "  output1 ---> last_accuracy, final accuracy number for training data (int)\n",
    "  output2 ---> val_accuracy, final accuracy number for validation data (int)\n",
    "  '''\n",
    "\n",
    "  #Build model architecture\n",
    "  model = Sequential()\n",
    "  model.add(Dense(hidden, activation = 'relu', input_shape = (input_shape,)))\n",
    "  for i in range(hidden_layers - 1):\n",
    "    model.add(Dense(hidden, activation = 'relu'))\n",
    "  model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "  #Compile the model\n",
    "  model.compile(optimizer ='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  #Fit model\n",
    "  history = model.fit(X, y, epochs = epochs, batch_size = batch, validation_data = (X_val, y_val))\n",
    "\n",
    "  #Evaluate model\n",
    "  loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "  #For graphics extract last accuracy\n",
    "  last_accuracy = history.history['accuracy'][-1]\n",
    "  val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "  return last_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QZkYCSAEXzq"
   },
   "source": [
    "### Complex model 1\n",
    "MatchPyramid is a semantic matching task developed by Microsoft [2]. The algorithm represents the search and article as matrices and calculates the element-wise product of these matrices.\n",
    "\n",
    "The algorithm contains a complex architecture including embedding, convolutional, and pooling layers. After passing through those layers it outputs a matching score indicating how relevant the article is to the search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziYlTE_3Ea89"
   },
   "outputs": [],
   "source": [
    "def matchPyramid (X_train_article, X_train_topic, y_train, X_val_article, X_val_topic, y_val, input_shape, vocab_size, epochs = 10, embedding_dim = 100):\n",
    "  '''\n",
    "  X_train_article ---> training data for articles tokenised (numpy array)\n",
    "  X_train_topic ---> training data for searches tokenised (numpy array)\n",
    "  y_train ---> labels of training data (numpy array)\n",
    "  X_val_article ---> validation data for articles tokenised (numpy array)\n",
    "  X_val_topic ---> validation data for searches tokenised (numpy array)\n",
    "  y_val ---> labels of validation data (numpy array)\n",
    "  input_shape ---> number of neurons in input layer (int)\n",
    "  epochs ---> number of epochs that the network is trained (int)\n",
    "  embedding_dim ---> number of neurons in the embedding layers (int)\n",
    "  output1 ---> last_accuracy, final accuracy number for training data (int)\n",
    "  output2 ---> val_accuracy, final accuracy number for validation data (int)\n",
    "  '''\n",
    "\n",
    "  # Input layers\n",
    "    input_article = Input(shape=(input_shape,))\n",
    "    input_topic = Input(shape=(input_shape,))\n",
    "    def build_matchpyramid_model(input_shape, vocab_size, embedding_dim=100, num_filters=16, kernel_size=(3, 3), output_size=1):\n",
    "      # Embedding layer\n",
    "      embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
    "      embedded_article = embedding_layer(input_article)\n",
    "      embedded_topic = embedding_layer(input_topic)\n",
    "\n",
    "      # Reshape inputs to add channel dimension\n",
    "      reshape_layer = Reshape((input_shape, embedding_dim, 1))\n",
    "      reshaped_article = reshape_layer(embedded_article)\n",
    "      reshaped_topic = reshape_layer(embedded_topic)\n",
    "\n",
    "      # Convolutional layers\n",
    "      convolution_layer = Convolution2D(filters=num_filters, kernel_size=kernel_size, activation='relu')\n",
    "      conv_article = convolution_layer(reshaped_article)\n",
    "      conv_topic = convolution_layer(reshaped_topic)\n",
    "\n",
    "      # Max pooling layers\n",
    "      max_pooling_layer = MaxPooling2D(pool_size=(2, 2))\n",
    "      pool_article = max_pooling_layer(conv_article)\n",
    "      pool_topic = max_pooling_layer(conv_topic)\n",
    "\n",
    "      # Flatten layers\n",
    "      flatten_layer = Flatten()\n",
    "      flat_article = flatten_layer(pool_article)\n",
    "      flat_topic = flatten_layer(pool_topic)\n",
    "\n",
    "      # Merge layers\n",
    "      merged_layer = Dense(64, activation='relu')(concatenate([flat_article, flat_topic]))\n",
    "\n",
    "      # Output layer\n",
    "      output_layer = Dense(output_size, activation='sigmoid')(merged_layer)\n",
    "\n",
    "      #Compile the model\n",
    "      model = Model(inputs=[input_article, input_topic], outputs=output_layer)\n",
    "      model.compile(optimizer ='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "      return model\n",
    "\n",
    "    #Create model\n",
    "    model = build_matchpyramid_model(input_shape, vocab_size, embedding_dim)\n",
    "\n",
    "    #Fit model\n",
    "    history = model.fit([X_train_article, X_train_topic], y_train, validation_data=([X_val_article, X_val_topic], y_val), epochs=epochs, batch_size=32)\n",
    "\n",
    "    #Evaluate model\n",
    "    loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "    #Extract last accuracy\n",
    "    last_accuracy = history.history['accuracy'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    return last_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hu6wZKbWV_N"
   },
   "outputs": [],
   "source": [
    "#Function to associate relevance based on match connections and a threshold\n",
    "def map_to_relevance(y_pred, threshold=0.5):\n",
    "  '''\n",
    "  y_pred ---> list of values between 0 and 1 (list)\n",
    "  threshold ---> value between 0 and 1 (float)\n",
    "  output ---> list of relevance 0 and 1 (list)\n",
    "  '''\n",
    "    connectedness_predictions = []\n",
    "    for pred in y_pred:\n",
    "        if pred >= threshold:\n",
    "            connectedness_predictions.append(1)  # Connected\n",
    "        else:\n",
    "            connectedness_predictions.append(0)  # Not connected\n",
    "    return connectedness_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SAO_cjvEbVa"
   },
   "source": [
    "### Complex model 2\n",
    "This custom complex model creates tailored LSTM models for different groups of searches, which are related to each other.\n",
    "\n",
    "It begins by combining all data into a single DataFrame, and clusters the data based on the searches using k-means clustering. For each cluster it creates a separate LSTM model, with a pre-determined core LSTM layer with 64 memory units. Finishing with a sigmoid output layer determining relevance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UyIJ3zYEfOt"
   },
   "outputs": [],
   "source": [
    "# Define LSTM model architecture\n",
    "def create_lstm_model(vocab_size, max_seq_length):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=128, input_length=max_seq_length),\n",
    "        LSTM(64),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5BEda-ZUrBz"
   },
   "outputs": [],
   "source": [
    "def clusters(X, y, X_val, y_val, vocab_size, k=20, epoch=10, seed=42):\n",
    "  '''\n",
    "  X ---> training data tokenised (numpy array)\n",
    "  y ---> labels of training data (numpy array)\n",
    "  X_val ---> validation data tokenised (numpy array)\n",
    "  y_val ---> labels of validation data (numpy array)\n",
    "  vocab size ---> number of tokens in vocabulary (int)\n",
    "  k ---> number of clusters (int)\n",
    "  epoch ---> number of epochs that the network is trained (int)\n",
    "  seed ---> selection of random seed that will be used (int)\n",
    "  output1 ---> fitted lstm model (obj)\n",
    "  '''\n",
    "    # Convert arrays to DataFrames\n",
    "    X = pd.DataFrame(X)\n",
    "    X_val = pd.DataFrame(X_val)\n",
    "\n",
    "    # Concatenate the target values for training and validation\n",
    "    judge = np.concatenate((y, y_val))\n",
    "\n",
    "    # Add 'train' and 'val' labels to the data\n",
    "    X['status'] = 'train'\n",
    "    X_val['status'] = 'val'\n",
    "\n",
    "    # Concatenate the DataFrames\n",
    "    all_X = pd.concat([X, X_val], ignore_index=True)\n",
    "\n",
    "    # Perform clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=seed)\n",
    "    cluster_labels = kmeans.fit_predict(all_X.drop(columns=['status']))\n",
    "\n",
    "    # Train LSTM models for each cluster\n",
    "    lstm_models = {}\n",
    "    acc_train = []\n",
    "    acc_val = []\n",
    "    for cluster in range(k):\n",
    "        cluster_df = all_X[cluster_labels == cluster]\n",
    "        texts = cluster_df.drop(columns=['status'])\n",
    "\n",
    "        # Convert DataFrame to a list of sequences\n",
    "        texts_list = [text.tolist() for _, text in texts.iterrows()]\n",
    "\n",
    "        # Pad sequences to ensure consistent length\n",
    "        max_seq_length = 100\n",
    "        texts_padded = pad_sequences(texts_list, maxlen=max_seq_length)\n",
    "\n",
    "        # Extract judgments for the current cluster\n",
    "        cluster_judgments = judge[cluster_labels == cluster]\n",
    "\n",
    "        # Convert X_val to float32\n",
    "        X_val_values = X_val.values.astype('float32')\n",
    "\n",
    "        # Convert y_val to float32\n",
    "        y_val_float32 = y_val.astype('float32')\n",
    "\n",
    "        # Train LSTM model\n",
    "        lstm_model = create_lstm_model(vocab_size, max_seq_length)\n",
    "        history = lstm_model.fit(texts_padded, cluster_judgments, validation_data=(X_val_values, y_val_float32), epochs=epoch, batch_size=32)\n",
    "        lstm_models[cluster] = lstm_model\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZm5vkfaEgod"
   },
   "source": [
    "## Results\n",
    "### Training the models\n",
    "\n",
    "In order to train our models we condense our input attributes into 4:\n",
    "\n",
    "*   `article`: concatenation of `title` and `body`\n",
    "*   `search`: concatenation of `topic_title`, `narrative`, and `description`\n",
    "*   `relevant`: labelled relevance\n",
    "*   `topic_id`: relevant unique topic identifier (for validation set split purposes)\n",
    "\n",
    "The attributes `article` and `search` are constructed separately as some of our models account for two separate entries for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dzUcZfgJvW2"
   },
   "outputs": [],
   "source": [
    "#Function to create condensed data\n",
    "def condensed (X):\n",
    "  '''\n",
    "  X --> train or test data (Pandas dataframe). Must contain `title`, `body`, `topic`, `narrative`, `description` and `topic_id` attributes\n",
    "  output --> condensed data frame 3 attributes if train, 2 attributes if test (Pandas dataframe)\n",
    "  '''\n",
    "  #Ensure all NaN values and floats can be processed as strings\n",
    "  df = X.astype(str)\n",
    "\n",
    "  #Check if this is a test or a training set\n",
    "  if 'judgement' in df.columns:\n",
    "    data = {'article': X['title'] + X['body'],\n",
    "              'search': X['topic'] + X['narrative'] + X['description'],\n",
    "              'relevant': X['judgement']}\n",
    "  else:\n",
    "    data = {'article': X['title'] + X['body'],\n",
    "              'search': X['topic'] + X['narrative'] + X['description']}\n",
    "  return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZJp7bshMyjO"
   },
   "source": [
    "To be able for the machine to interpret our data it must be vectorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKEdqEwLL-JW"
   },
   "outputs": [],
   "source": [
    "#Function to tokenise and convert train data into sequences + padding to ensure the same length\n",
    "def token_train(X_train, X_val):\n",
    "    '''\n",
    "    X_train --> condensed train data (Pandas dataframe). Must contain `article` and `search` attributes\n",
    "    X_val --> condensed validation data (Pandas dataframe). Must contain `article` and `search` attributes\n",
    "    output --> list of numpy array of 'article' data tokenised and padded, and numpy array of 'search' data tokenised and padded\n",
    "    '''\n",
    "    print(\"Sample of input data:\")\n",
    "    print(X_train.head())\n",
    "\n",
    "    #Ensure all elements are strings\n",
    "    X_train = X_train.astype(str)\n",
    "    X_val = X_val.astype(str)\n",
    "\n",
    "    # Combine training and validation data for tokenization\n",
    "    all_text = X_train['article'] + X_train['search'] + X_val['article'] + X_val['search']\n",
    "\n",
    "    # Tokenize\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_text)\n",
    "\n",
    "    # Convert to sequences and pad sequences to the maximum length\n",
    "    sequences_train_article = tokenizer.texts_to_sequences(X_train['article'])\n",
    "    sequences_train_search = tokenizer.texts_to_sequences(X_train['search'])\n",
    "    sequences_val_article = tokenizer.texts_to_sequences(X_val['article'])\n",
    "    sequences_val_search = tokenizer.texts_to_sequences(X_val['search'])\n",
    "\n",
    "    max_seq_length = max(\n",
    "        max(len(seq) for seq in sequences_train_article),\n",
    "        max(len(seq) for seq in sequences_train_search),\n",
    "        max(len(seq) for seq in sequences_val_article),\n",
    "        max(len(seq) for seq in sequences_val_search)\n",
    "    )\n",
    "\n",
    "    article_padded_train = pad_sequences(sequences_train_article, maxlen=max_seq_length)\n",
    "    search_padded_train = pad_sequences(sequences_train_search, maxlen=max_seq_length)\n",
    "    article_padded_val = pad_sequences(sequences_val_article, maxlen=max_seq_length)\n",
    "    search_padded_val = pad_sequences(sequences_val_search, maxlen=max_seq_length)\n",
    "\n",
    "    print(\"Tokenized sequences:\")\n",
    "    print(sequences_train_article[:5])  # Print the first 5 sequences\n",
    "    print(\"Sequence lengths:\")\n",
    "    print([len(seq) for seq in sequences_train_article])  # Print the lengths of tokenized sequences\n",
    "\n",
    "    return [article_padded_train, search_padded_train], [article_padded_val, search_padded_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zxeGPLpSNPQ"
   },
   "outputs": [],
   "source": [
    "#Function to tokenise and convert test and train data into sequences + padding to ensure the same length\n",
    "#Needs to include train and test data when used on this dataset so vectorisation is consistent throughout\n",
    "\n",
    "\n",
    "def token_test(X, Y):\n",
    "    '''\n",
    "    X --> condensed train data (Pandas dataframe). Must contain `article` and `search` attributes\n",
    "    Y --> condensed test data (Pandas dataframe). Must contain `article` and `search` attributes\n",
    "    output --> two variables storing list of numpy array of 'article' data tokenised and padded, and numpy array of 'search' data tokenised and padded\n",
    "    '''\n",
    "    # Ensure all elements are strings\n",
    "    X = X.astype(str)\n",
    "    Y = Y.astype(str)\n",
    "\n",
    "    # Combine training and testing data for calculating max sequence length and tokens\n",
    "    combined_texts = pd.concat([X['article'], Y['article']]) + pd.concat([X['search'], Y['search']])\n",
    "\n",
    "    # Tokenize\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(combined_texts)\n",
    "\n",
    "    # Convert to sequences\n",
    "    sequences_article = tokenizer.texts_to_sequences(X['article'])\n",
    "    sequences_search = tokenizer.texts_to_sequences(X['search'])\n",
    "    sequences_article_test = tokenizer.texts_to_sequences(Y['article'])\n",
    "    sequences_search_test = tokenizer.texts_to_sequences(Y['search'])\n",
    "\n",
    "    # Debugging: print out sequence lengths\n",
    "    print(\"Sequence lengths before padding:\")\n",
    "    print(\"Train Article:\", [len(seq) for seq in sequences_article])\n",
    "    print(\"Train Search:\", [len(seq) for seq in sequences_search])\n",
    "    print(\"Test Article:\", [len(seq) for seq in sequences_article_test])\n",
    "    print(\"Test Search:\", [len(seq) for seq in sequences_search_test])\n",
    "\n",
    "    # Pad sequences to same length\n",
    "    max_seq_length = max(len(seq) for seq in sequences_article + sequences_search + sequences_article_test + sequences_search_test)\n",
    "    article_padded = pad_sequences(sequences_article, maxlen=max_seq_length)\n",
    "    search_padded = pad_sequences(sequences_search, maxlen=max_seq_length)\n",
    "    article_padded_test = pad_sequences(sequences_article_test, maxlen=max_seq_length)\n",
    "    search_padded_test = pad_sequences(sequences_search_test, maxlen=max_seq_length)\n",
    "\n",
    "    # Debugging: print out shape of padded arrays\n",
    "    print(\"Shape of padded arrays:\")\n",
    "    print(\"Train Article:\", article_padded.shape)\n",
    "    print(\"Train Search:\", search_padded.shape)\n",
    "    print(\"Test Article:\", article_padded_test.shape)\n",
    "    print(\"Test Search:\", search_padded_test.shape)\n",
    "\n",
    "    # Organize return data\n",
    "    to_train = [np.array(article_padded), np.array(search_padded)]\n",
    "    to_test = [np.array(article_padded_test), np.array(search_padded_test)]\n",
    "\n",
    "    return to_train, to_test, tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXSY8CCWYB5S"
   },
   "outputs": [],
   "source": [
    "#Function to separate x and y inputs for data training and fitting\n",
    "def separate_train (X, down = True, size = 0.2, seed = 42):\n",
    "  '''\n",
    "  X ---> train data (Pandas dataframe). Must contain `title`, `body`, `topic`, `narrative`, `description` and `topic_id` attributes\n",
    "  down ---> indicate whether we want to apply downsampling on data (bool). Default True\n",
    "  size ---> size of our generated topic selection for validation data (float). Default 0.2\n",
    "  seed ---> selection of random seed that will be used (int)\n",
    "  output ---> X_train_article, X_val_article, X_train_topic, X_val_topic, y_train, y_val all numpy arrays\n",
    "  '''\n",
    "  #Downsample if specified\n",
    "  if down:\n",
    "    X = down_sampling(X, seed)\n",
    "\n",
    "  #Separate into training and validation\n",
    "  train, val = validation_split(X, size, seed)\n",
    "\n",
    "  #Condense dataframe\n",
    "  con_train = condensed(train)\n",
    "  con_val = condensed(val)\n",
    "\n",
    "  #Separate judgement from the rest of the data\n",
    "  y_train, y_val =  np.array(con_train['relevant']), np.array(con_val['relevant'])\n",
    "  x_train, x_val =  con_train.drop('relevant', axis=1), con_val.drop('relevant', axis=1)\n",
    "\n",
    "\n",
    "  #Implement tokenisation of X\n",
    "  tokens_train, tokens_val, tokenizer = token_test(x_train, x_val)\n",
    "\n",
    "  #Separate into article and topics\n",
    "  X_train_article = np.array(tokens_train[0])\n",
    "  X_val_article = np.array(tokens_val[0])\n",
    "  X_train_search = np.array(tokens_train[1])\n",
    "  X_val_search = np.array(tokens_val[1])\n",
    "\n",
    "  print(np.array(tokens_train).shape, np.array(tokens_val).shape)\n",
    "\n",
    "  return X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_LmCRPouQeo"
   },
   "outputs": [],
   "source": [
    "#Function to separate x and y inputs for data training and fitting\n",
    "def separate_test (X, Y, down = True, size = 0.2, seed = 42):\n",
    "  '''\n",
    "  X ---> train data (Pandas dataframe). Must contain `title`, `body`, `topic`, `narrative`, `description` and `topic_id` attributes\n",
    "  Y ---> train data (Pandas dataframe). Must contain `title`, `body`, `topic`, `narrative`, `description` and `topic_id` attributes\n",
    "  down ---> indicate whether we want to apply downsampling on data (bool). Default True\n",
    "  size ---> size of our generated topic selection for validation data (float). Default 0.2\n",
    "  seed ---> selection of random seed that will be used (int)\n",
    "  output ---> X_train_article, X_test_article, X_train_search, X_test_search, y_train all numpy arrays\n",
    "  '''\n",
    "  #Downsample if specified\n",
    "  if down:\n",
    "    X = down_sampling(X, seed)\n",
    "\n",
    "  #Condense dataframe\n",
    "  con_train = condensed(X)\n",
    "  con_test = condensed(Y)\n",
    "\n",
    "  #Separate judgement from the rest of the data\n",
    "  y_train=  np.array(con_train['relevant'])\n",
    "  x_train, x_test =  con_train.drop('relevant', axis=1), con_test\n",
    "\n",
    "\n",
    "  #Implement tokenisation of X\n",
    "  tokens_train, tokens_test = token_test(x_train, x_test)\n",
    "\n",
    "  #Separate into article and topics\n",
    "  X_train_article = np.array(tokens_train[0])\n",
    "  X_test_article = np.array(tokens_test[0])\n",
    "  X_train_search = np.array(tokens_train[1])\n",
    "  X_test_search = np.array(tokens_test[1])\n",
    "\n",
    "  return X_train_article, X_test_article, X_train_search, X_test_search, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UQDOLA33Ki4"
   },
   "source": [
    "### \"Sparse\" and Standard Machine Learning model\n",
    "\n",
    "The sparse benchmark acts in the expected manner: circa 84% without down sampling and circa 50% for the down sampled data.\n",
    "\n",
    "As for the standard benchmark, we attempted multiple models including linear models, logistic regressions, and random forests. Some of the models, like logistic regression, did not manage to reach convergence. The best performing model for our validation set was random forests, which performed slightly above the sparse benchmark: circa 86% without down sampling and circa 53% for the down sampled data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyEMGxDG3hEZ"
   },
   "outputs": [],
   "source": [
    "#Sparse and standard validation with down sampling\n",
    "acc_ds_sparse, acc_ds_standard = [], []\n",
    "for i in range(10):\n",
    "    X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train(df_train_processed, down=True, size=0.2, seed=i)\n",
    "    X_train = np.concatenate((X_train_article, X_train_search), axis=1)\n",
    "    X_val = np.concatenate((X_val_article, X_val_search), axis=1)\n",
    "    print(X_train.shape)\n",
    "    pred_sparse = sparse(X_val)\n",
    "    acc_ds_sparse.append(accuracy_score(y_val, pred_sparse))\n",
    "    #pred_standard = standard(X_train, y_train, X_val)\n",
    "    pred_standard = forest(X_train, y_train, X_val, 100)\n",
    "    acc_ds_standard.append(accuracy_score(y_val, pred_standard))\n",
    "print(acc_ds_sparse, acc_ds_standard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgK1K3OEW3vm"
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(acc_ds_standard, acc_ds_sparse, marker='o', label='Sparse Accuracy')\n",
    "plt.title('Sparse and Standard Accuracy (DownSampling)')\n",
    "plt.xlabel('Sparse')\n",
    "plt.ylabel('')\n",
    "plt.xscale('log')  # Setting x-axis to logarithmic scale\n",
    "plt.xticks(indices, labels=[str(i) for i in indices])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUIUAvnQ-k7Z"
   },
   "outputs": [],
   "source": [
    "#Sparse and standard validation without down sampling\n",
    "acc_nds_sparse, acc_nds_standard = [], []\n",
    "for i in range(10):\n",
    "    X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train(df_train_processed, down=False, size=0.2, seed=i)\n",
    "    X_train = np.concatenate((X_train_article, X_train_search), axis=1)\n",
    "    X_val = np.concatenate((X_val_article, X_val_search), axis=1)\n",
    "    print(X_train.shape)\n",
    "    pred_sparse = sparse(X_val)\n",
    "    acc_nds_sparse.append(accuracy_score(y_val, pred_sparse))\n",
    "    #pred_standard = standard(X_train, y_train, X_val)\n",
    "    pred_standard = forest(X_train, y_train, X_val, 100)\n",
    "    acc_nds_standard.append(accuracy_score(y_val, pred_standard))\n",
    "print(acc_nds_sparse, acc_nds_standard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcUQcLU-XhXv"
   },
   "outputs": [],
   "source": [
    "#Graphs\n",
    "indices = [i for i in range(10)]\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(indices, acc_nds_sparse, marker='o', label='Sparse Accuracy')\n",
    "plt.plot(indices, acc_nds_standard, marker='o', label='Standard Accuracy')\n",
    "plt.title('Sparse and Standard Accuracy (no DownSampling)')\n",
    "plt.xlabel('Seed')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xscale('log')  # Setting x-axis to logarithmic scale\n",
    "plt.xticks(indices, labels=[str(i) for i in indices])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjOlAfnr_j5O"
   },
   "source": [
    "### 3NN\n",
    "We run a three-layer neural network, where we modify the number of neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0vXE_Kz_kCl"
   },
   "outputs": [],
   "source": [
    "X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train (df_train_processed, down = True, size = 0.2, seed = 42)\n",
    "\n",
    "X_train, X_val = X_train_article + X_train_search, X_val_article + X_val_search\n",
    "\n",
    "X_train = np.concatenate((X_train_article, X_train_search), axis=1)\n",
    "X_val = np.concatenate((X_val_article, X_val_search), axis=1)\n",
    "\n",
    "\n",
    "#Storing second dimension for initialisation\n",
    "second_dimension = X_train.shape[1]\n",
    "\n",
    "train_acc_3d = []\n",
    "val_acc_3d =[]\n",
    "for i in range(12):\n",
    "  last_accuracy, val_accuracy = threeNN(X_train, y_train, X_val, y_val, 2**i, second_dimension, 10, 32)\n",
    "  train_acc_3d.append(last_accuracy)\n",
    "  val_acc_3d.append(val_accuracy)\n",
    "\n",
    "print(train_acc_3d)\n",
    "print(val_acc_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckJiU-AIFwtQ"
   },
   "outputs": [],
   "source": [
    "X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train (df_train_processed, down = False, size = 0.2, seed = 42)\n",
    "\n",
    "X_train, X_val = X_train_article + X_train_search, X_val_article + X_val_search\n",
    "\n",
    "X_train = np.concatenate((X_train_article, X_train_search), axis=1)\n",
    "X_val = np.concatenate((X_val_article, X_val_search), axis=1)\n",
    "\n",
    "\n",
    "#Storing second dimension for initialisation\n",
    "second_dimension = X_train.shape[1]\n",
    "\n",
    "train_acc_3nd = []\n",
    "val_acc_3nd =[]\n",
    "for i in range(12):\n",
    "  last_accuracy, val_accuracy = threeNN(X_train, y_train, X_val, y_val, 2**i, second_dimension, 10, 32)\n",
    "  train_acc_3nd.append(last_accuracy)\n",
    "  val_acc_3nd.append(val_accuracy)\n",
    "\n",
    "print(train_acc_3nd)\n",
    "print(val_acc_3nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vv7v5RdpDB7O"
   },
   "outputs": [],
   "source": [
    "#Graphs\n",
    "indices = [2**i for i in range(12)]\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(indices, train_acc_3d, marker='o', label='Training Accuracy')\n",
    "plt.plot(indices, val_acc_3d, marker='o', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy vs. Neurons in Hidden Layer (DownSampling)')\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xscale('log')  # Setting x-axis to logarithmic scale\n",
    "plt.xticks(indices, labels=[str(i) for i in indices])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrQqQsu6qZVc"
   },
   "outputs": [],
   "source": [
    "#Graphs\n",
    "indices = [2**i for i in range(12)]\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(indices, train_acc_3nd, marker='o', label='Training Accuracy')\n",
    "plt.plot(indices, val_acc_3nd, marker='o', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy vs. Neurons in Hidden Layer (No DownSampling)')\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xscale('log')  # Setting x-axis to logarithmic scale\n",
    "plt.xticks(indices, labels=[str(i) for i in indices])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD2EoJdhnGAA"
   },
   "source": [
    "As can be seen from the accuracy plots, for both down sampling and no down sampling, when we increase the number of neurons beyond a threshold of 128 neurons, we observe over-fitting from our model. The optimal accuracy dependent on the number of neurons for our training and validation sets ranges between 16 and 32 neurons in our hidden layer.\n",
    "\n",
    "The accuracy of this model is low, close to a random relevance allocation. In the case of the non-down sampling implementation, always performing below the sparse benchmark.\n",
    "\n",
    "The next step to improve our model is to include more hidden layers to improve predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTzmiwqHPyYB"
   },
   "source": [
    "### DNN\n",
    "As can be seen from the graphs, increasing the number of hidden layers improves training accuracy, but they do not significantly improve the performance on the validation set. This finding is consistent with other research in the field that shows no significant improvements [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sy-n5eVwP1LN"
   },
   "outputs": [],
   "source": [
    "X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train (df_train_processed, down = True, size = 0.2, seed = 42)\n",
    "\n",
    "X_train, X_val = X_train_article + X_train_search, X_val_article + X_val_search\n",
    "\n",
    "X_train = np.concatenate((X_train_article, X_train_search), axis=1)\n",
    "X_val = np.concatenate((X_val_article, X_val_search), axis=1)\n",
    "\n",
    "\n",
    "#Storing second dimension for initialisation\n",
    "second_dimension = X_train.shape[1]\n",
    "\n",
    "train_acc_dnnds = []\n",
    "val_acc_dnnds =[]\n",
    "for i in range(8):\n",
    "  last_accuracy, val_accuracy = DNN(X_train, y_train, X_val, y_val, 16, i+3, second_dimension, 30, 32)\n",
    "  train_acc_dnnds.append(last_accuracy)\n",
    "  val_acc_dnnds.append(val_accuracy)\n",
    "\n",
    "print(train_acc_dnnds)\n",
    "print(val_acc_dnnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QcgxoKtTVN1"
   },
   "outputs": [],
   "source": [
    "X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train (df_train_processed, down = False, size = 0.2, seed = 42)\n",
    "\n",
    "X_train, X_val = X_train_article + X_train_search, X_val_article + X_val_search\n",
    "\n",
    "X_train = np.concatenate((X_train_article, X_train_search), axis=1)\n",
    "X_val = np.concatenate((X_val_article, X_val_search), axis=1)\n",
    "\n",
    "\n",
    "#Storing second dimension for initialisation\n",
    "second_dimension = X_train.shape[1]\n",
    "\n",
    "train_acc_dnnnds = []\n",
    "val_acc_dnnnds =[]\n",
    "for i in range(8):\n",
    "  last_accuracy, val_accuracy = DNN(X_train, y_train, X_val, y_val, 16, i+3, second_dimension, 30, 32)\n",
    "  train_acc_dnnnds.append(last_accuracy)\n",
    "  val_acc_dnnnds.append(val_accuracy)\n",
    "\n",
    "print(train_acc_dnnnds)\n",
    "print(val_acc_dnnnds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC8FV8XDdqbk"
   },
   "source": [
    "From these models’ results prove we need to account for the fact that there is no significant improvement from deeper neural networks with respect to a standard machine learning approach. We hypothesise a reason for this lack of improvement is the fact there are two inputs to determine relevance, and our Standard Machine Learning, 3-layer Neural Networks, and Deep Neural Networks model only account for a single input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpFdI-BfY8fd"
   },
   "source": [
    "### MatchPyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1o7V_prVY84X"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train (df_train_processed, down = False, size = 0.2, seed = i)\n",
    "\n",
    "  #Storing second dimension for initialisation\n",
    "  second_dimension = max(X_train_article.shape[1], X_train_search.shape[1])\n",
    "  vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "  matchPyramid(X_train_article, X_train_search, y_train, X_val_article, X_val_search, y_val, second_dimension, vocab_size, epochs = 2, embedding_dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Bg94I8UneCp"
   },
   "outputs": [],
   "source": [
    "X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train (df_train_processed, down = True, size = 0.2, seed = 1)\n",
    "\n",
    "#Storing second dimension for initialisation\n",
    "second_dimension = max(X_train_article.shape[1], X_train_search.shape[1])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "matchPyramid(X_train_article, X_train_search, y_train, X_val_article, X_val_search, y_val, second_dimension, vocab_size, epochs = 4, embedding_dim = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEY4VjDFpA6z"
   },
   "source": [
    "MatchPyramid’s performance is significantly improving the sparse benchmark with an 88% accuracy. We tried several iterations of the MatchPyramid algorithm modifying the embedding dimension. The results were promising as the deviation in accuracy is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFFn0dxMnei7"
   },
   "source": [
    "### K-means\n",
    "\n",
    "We tested this custom model with three different algorithms after k-means clustering takes place. Linear Regression did not achieve significantly positive results. LSTM performed slightly better than the sparse benchmark. Whereas BERT underfitted the data, with a high tendency to predict irrelevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JposcJcAnhq4"
   },
   "outputs": [],
   "source": [
    "X_train_article, X_val_article, X_train_search, X_val_search, y_train, y_val, tokenizer = separate_train (df_train_processed, down = False, size = 0.2, seed = 42)\n",
    "\n",
    "X_train, X_val = X_train_article + X_train_search, X_val_article + X_val_search\n",
    "\n",
    "# X_train = np.concatenate((X_train_article, X_train_search), axis=1)\n",
    "# X_val = np.concatenate((X_val_article, X_val_search), axis=1)\n",
    "\n",
    "#Storing second dimension for initialisation\n",
    "second_dimension = max(X_train_article.shape[1], X_train_search.shape[1])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "#Storing second dimension for initialisation\n",
    "second_dimension = X_train.shape[1]\n",
    "\n",
    "train_acc, val_acc = clusters(X_train, y_train, X_val, y_val, vocab_size)\n",
    "\n",
    "print(train_acc)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqBAHa53pSMO"
   },
   "source": [
    "### Validation Results\n",
    "Validation data without DownSampling running these models with 10 different seeds\n",
    "\n",
    "| Model   | Average Accuracy    | Standard Deviation|\n",
    "|---------|---------------------|-------------|\n",
    "| Sparse Model  | 0.84116902 | 0.00548342|\n",
    "| Standard ML: Random Forests| 0.8646539 | 0.0011255|\n",
    "| 3-layer Neural Network| 0.83799| 0.019875|\n",
    "| Deep Neural Network (4 hidden)| 0.84084 | 0.0192229|\n",
    "| MatchPyramid | 0.879469319| 0.00032617|\n",
    "| k-means (LSTM) | 0.863246| 0.002375|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMnWw04nd0Im"
   },
   "source": [
    "### Test data without DownSampling\n",
    "| Model   | Kaggle Score Public Score         |\n",
    "|---------|----------------------------------|\n",
    "| Sparse Model  | 0.87305|\n",
    "| Standard ML: Linear Regression| 0.87278|\n",
    "| Standard ML: Random Forests| 0.86513 |\n",
    "| 3-layer Neural Network| 0.87168|\n",
    "| Deep Neural Network| 0.87305 |\n",
    "| MatchPyramid | 0.79634|\n",
    "| k-means (linear regression)| 0.84520|\n",
    "| k-means (LSTM) | 0.85558|\n",
    "| k-means (BERT) | 0.87250|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2xtZ-6xbymE"
   },
   "source": [
    "## Summary\n",
    "Throughout our model exploration and implementation we researched various machine learning and deep learning models. Some of the models included random forest classifiers, neural networks, MatchPyramid and a custom k-means + LSTM model. We also tested some pre-trained models and architectures, like BERT, LDA or DDSM.\n",
    "\n",
    "Our recommended model to approach relevance of text-based searches would be MatchPyramid.  The recommendation comes from the fact that MatchPyramid is the best performing model on the validation data, and with the least amount of deviation.\n",
    "\n",
    "The next potential steps would be the implementation of different models into an ensemble model. We tested this with some of our models in an ensemble voting classifier, which did not result to be more effective than the individual models. We still believe ensemble methods can mitigate the errors and biases of individual models.\n",
    "\n",
    "Another way in which we could improve performance through pre-trained text-processing neural networks, and customising them to our problem. A potential next step is to implement BERT processing, and freezing some of the trained network and training it with our data.\n",
    "\n",
    "Furthermore, we wish to implement further semantic and contextual processing to our text data in the pre-processing stages. These future steps we aim to achieve better predictions and extrapolate better to other search relevance problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3jw0NxnbyvF"
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Montufar, G. F., Pascanu, R., Cho, K., & Bengio, Y. (2014). On the number of linear regions of deep neural networks. In Advances in Neural Information Processing Systems (pp. 2924-2932)\n",
    "\n",
    "[2] Pang, L., Lan, Y., Guo, J., Xu, J., & Cheng, X. (2016). A Study of MatchPyramid Models on Ad-hoc Retrieval. arXiv preprint arXiv:1606.04648."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
